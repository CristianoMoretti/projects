{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5mb8FvvsbmuzGJrsfPA/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristianoMoretti/projects/blob/main/PyTorch_Tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-Main**"
      ],
      "metadata": {
        "id": "mUU7TjfXqfBY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CeIHPMjqSAz",
        "outputId": "79dbbabe-e201-463c-9327-a7d96630dba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "tensor([[0.8538, 0.9815, 0.9868],\n",
            "        [0.0448, 0.6392, 0.7228],\n",
            "        [0.3551, 0.3926, 0.7167],\n",
            "        [0.8901, 0.7337, 0.5682],\n",
            "        [0.7394, 0.5802, 0.6936]])\n",
            "False\n",
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n",
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "\n",
        "print(torch.__version__)\n",
        "\n",
        "x = torch.rand(5, 3)\n",
        "\n",
        "print(x)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "\n",
        " # Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-Tensor Basics**"
      ],
      "metadata": {
        "id": "znj7q9t5rJ2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=exaWOE8jvy8&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=2\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "x = torch.rand(3, 2)\n",
        "print(x)\n",
        "\n",
        "x = torch.empty(2, 2, 3)\n",
        "print(x)\n",
        "\n",
        "x = torch.ones(2, 2)\n",
        "print(x)\n",
        "\n",
        "print(x.dtype)\n",
        "\n",
        "x = torch.ones(2,2, dtype=torch.int16)\n",
        "print(x)\n",
        "print(x.size())\n",
        "\n",
        "x = torch.tensor([2.5, 0.1])\n",
        "print(x)\n",
        "\n",
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "z = torch.add(x, y)\n",
        "print(z)\n",
        "\n",
        "y.add_(x)\n",
        "print(y)\n",
        "\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "print(z)\n",
        "\n",
        "z = x * y\n",
        "z = torch.mul(x, y)\n",
        "y = y.mul_(x)\n",
        "print(z)\n",
        "print(y)\n",
        "\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(x[1, :])\n",
        "\n",
        "x = torch.rand(4, 4)\n",
        "print(x)\n",
        "\n",
        "y = x.view(16)\n",
        "print(y)\n",
        "y = x.view(-1)\n",
        "print(y)\n",
        "\n",
        "y = x.view(2, 8)\n",
        "print(y)\n",
        "y = x.view(-1, 8)\n",
        "print(y)\n",
        "\n",
        "# convert from numpy to torch and viceversa\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "# on the cpu they both point to teh same memory location and if I chnage one I also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# we can work on the gpu\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    # this will create the tensor on the GPU\n",
        "    x = torch.ones(5, device = device)\n",
        "    # or we can use the following\n",
        "    y = torch.ones(5)\n",
        "    # this will move the tensor from cpu to gpu\n",
        "    y = y.to(device)\n",
        "    # perform the computation on the gpu which is much faster\n",
        "    z = x + y\n",
        "    # z.numpy() wil retrun an error as numpy() an only be called on the cpu\n",
        "    z = z.to(\"cpu\")\n",
        "    z = z.numpy()"
      ],
      "metadata": {
        "id": "8s6mXgWarP5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3-Autograd Gradient Calculation**"
      ],
      "metadata": {
        "id": "_T_M9J7JrYYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=DbeIqrwb_dE&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=3\n",
        "\n",
        "import torch\n",
        "\n",
        "# the required_grad will tell pytorch to calculate the gradiens later on for the tensor during the optimization step\n",
        "x = torch.ones(5, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# whenever we are doing operations with this tensor pytorch will create a computational graph for us\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "# this will create a computational graph\n",
        "# with a technique called back propagation we can calculated the gradients\n",
        "# first we do a forward pass where we calculate the output y. If required_grad = True pytorch will store a funciton for us called addbackwards.\n",
        "# this function is used in the backpropagation to get the gradients\n",
        "# gradients will be calculated in the backward pass\n",
        "y = x + 2\n",
        "# this will show the AddBackward fucntion has been added to the oupput ot the grad_fn attribute\n",
        "print(y)\n",
        "\n",
        "# our gradient function will be multiplication backwards function\n",
        "z = y*y*2\n",
        "print(z)\n",
        "# our gradient function will be the mean backwards function\n",
        "# z = z.mean()\n",
        "# print(z)\n",
        "\n",
        "# when we want to calculate the gradient we will call (if the output is a scalar like for z.mean())\n",
        "# z.backward() # dz/dx\n",
        "# x has an attribut grad where the gradients are stored\n",
        "# print(x.grad)\n",
        "\n",
        "# if we dont use the mean z has size 1 x 3, now we need to pass an argument as z.backward() can only we used with scalar outputs, to calculate the gradients we need to vreate a vector of the same size.\n",
        "# The gardients are the product of the Jacobian matrix and the gradient vector\n",
        "# if the output is not a scalar value we must give a vector\n",
        "# most of timres the output will be a scalar\n",
        "v = torch.tensor([0.1, 1.0, 0.001], dtype = torch.float32)\n",
        "z.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# during trainibng we dont want to update the inputs just the weights, so we can call these different methods:\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():\n",
        "\n",
        "# if the function has a trailing underscore in pythoin it means it will modify the variable in place\n",
        "# x.requires_grad_(False)\n",
        "# OR\n",
        "# y = x.detach() # this will create a new tensor with the same values\n",
        "print(y)\n",
        "# OR wrap in a with statement\n",
        "# with torch.no_grad():\n",
        "#    y = x + 2\n",
        "#    print(y)\n",
        "\n",
        "# whenever we all this function y = x + 2 the gradient for this function will accumulate in the .grad attribute\n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "# say we have a trainign loop\n",
        "\n",
        "# first is only 1 iterations\n",
        "for epoch in range(3):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    # all the gradients accumulate after each iteration which is somethign we dont want, so we must zero the gradients to ensure gradients to not accumulate\n",
        "    print(weights.grad)\n",
        "    weights.grad.zero_()\n",
        "\n",
        "\n",
        "# pytorch built in optimiser\n",
        "optimiser = torch.optim.SGD([weights], lr = 0.01)\n",
        "optimiser.step()\n",
        "# this will do exactly the same, it will reset the gradients.\n",
        "# we must empty the gradient before performign the next operation\n",
        "optimiser.zero_grad()"
      ],
      "metadata": {
        "id": "okNrXwiJriAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4-Back Propagation**"
      ],
      "metadata": {
        "id": "bkUP25jwr6q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=3Kb0QS6z7WA&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=4\n",
        "\n",
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass and compute the loss\n",
        "y_hat = w * x\n",
        "loss = (y_hat-y)**2\n",
        "\n",
        "print(loss)\n",
        "\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "### updates weights\n",
        "### next forward and backwards"
      ],
      "metadata": {
        "id": "zaJs1S7bsAYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5-Gradient Descent**"
      ],
      "metadata": {
        "id": "g9XVctZfsDTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=E-I2DNVzQLg&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=5\n",
        "\n",
        "# this can be done in 4 different ways\n",
        "\n",
        "print('CASE 1')\n",
        "\n",
        "'''\n",
        "Prediction: Manually\n",
        "Gradient Computation: Manually\n",
        "Loss Computation: Manually\n",
        "Parameter updates: Manually\n",
        "'''\n",
        "\n",
        "# I am using linear regression\n",
        "import numpy as np\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = np.array([1, 2, 3, 4], dtype = np.float32)\n",
        "# csince our formula is 2x\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "# our weight initially is:\n",
        "w= 0.0\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "    return w * x\n",
        "# loss = MSE\n",
        "def loss(y, y_predicted):\n",
        "    return ((y_predicted-y)**2).mean()\n",
        "\n",
        "\n",
        "# gradient\n",
        "# MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N 2x (w*x -y)\n",
        "\n",
        "def gradient(x, y, y_predicted):\n",
        "    return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # prediction = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights (we go in the negative direction of the training)\n",
        "    w -= learning_rate *dw\n",
        "\n",
        "    if epoch % 1 ==0: # I am printing every step)\n",
        "        print(f'epoch{epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Prediction: Manually\n",
        "Gradient Computation: Autograd\n",
        "Loss Computation: Manually\n",
        "Parameter updates: Manually\n",
        "'''\n",
        "print('CASE 2')\n",
        "\n",
        "# I am using linear regression\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
        "# our weight initially is 0:\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "    return w * x\n",
        "# loss = MSE\n",
        "def loss(y, y_predicted):\n",
        "    return ((y_predicted-y)**2).mean()\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "# the backward propagation is not as exact as the numeric propagation, so I will need more iterations\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # prediction = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # gradients = backward pass\n",
        "    # this wiull calculate the gradients respect to w\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    # this should be not part of our gradient tracking graph (we need to use original w not w containing gradient updates), so I need to wrap with a torch.no_grad statement\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero gradients\n",
        "    # we must zero the gradients, otherwise each iteration the gradient will be calculted and accumulate in w.grad attribute\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 1 ==0: # I am printing every step)\n",
        "        print(f'epoch{epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "print('CASE 3')\n",
        "'''\n",
        "Prediction: Manually\n",
        "Gradient Computation: Autograd\n",
        "Loss Computation: PyTorch Loss\n",
        "Parameter updates: PyTorch Optimizer\n",
        "'''\n",
        "\n",
        "# respect to case 2 we need to replace the loss and optimizatio method\n",
        "import torch.nn as nn\n",
        "\n",
        "# General training pipeline in PyTorch, typically we have 3 steps\n",
        "# 1) Design our model (input size, output size, forward pass with all the operations and layers)\n",
        "# 2) Constract the loss and the optimizer\n",
        "# 3) Training Loop\n",
        "#     - forward pass: compute prediction\n",
        "#     - backward pass: we get the gradients\n",
        "#     - update weights\n",
        "#     - we iterate this a couple of times until we are done\n",
        "\n",
        "\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)\n",
        "# our weight initially is 0:\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "    return w * x\n",
        "# loss = MSE\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "optimizer = torch.optim.SGD([w],  lr = learning_rate)\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "for epoch in range(n_iters):\n",
        "    # prediction = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # gradients = backward pass\n",
        "    # this wiull calculate the gradients respect to w\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "\n",
        "    # we do not need to optimise the weights manually anymore, I can use an optimiser.step operation\n",
        "    '''\n",
        "        with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    '''\n",
        "    optimizer.step()\n",
        "\n",
        "    # we still have to zero the gradients\n",
        "    # we must zero the gradients, otherwise each iteration the gradient will be calculted and accumulate in w.grad attribute\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 1 ==0: # I am printing every step)\n",
        "        print(f'epoch{epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "print('CASE 4') # we replace our manaully implemented forward method with a PyTorch model\n",
        "'''\n",
        "Prediction: PyTorch Model\n",
        "Gradient Computation: Autograd\n",
        "Loss Computation: PyTorch Loss\n",
        "Parameter updates: PyTorch Optimizer\n",
        "'''\n",
        "\n",
        "# using the Torch model inputs need to be  different shape (2D array now)\n",
        "# the number of rows is the numbe of samples and for each row we have the number of features.\n",
        "# here we have 4 samples and 1 features\n",
        "# the same for our 4, it needs to have the same shape\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32)\n",
        "\n",
        "X_test = torch.tensor([5], dtype = torch.float32) # we take a sample for testing, the sample is an array of values (in this case there is only 1). It has to be a Tensor as PyTorch works with tensors.\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "# we define our model, we need an input size and an output size\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# our weight initially is 0:\n",
        "# we don't need the weights tensor anymore as out model knows the parameters\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "# model prediction, typically we have to designed it for ourselves but as this is very trivial we use the Linear model from PyTorch\n",
        "'''\n",
        "def forward(x):\n",
        "    return w * x\n",
        "'''\n",
        "# in this case we did not have to come up with a model ourselves and this model was already provided by PyTorch\n",
        "model = nn.Linear(in_features = input_size, out_features = output_size)\n",
        "\n",
        "\n",
        "# if we need a custom model, we need to derive it from nn.Module\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        # this is how we call the super constructor of the parent class\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "# loss = MSE\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "learning_rate = 0.01\n",
        "n_iters = 10\n",
        "# we repalce weights entered manually with model.parameters\n",
        "# optimizer = torch.optim.SGD([w],  lr = learning_rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(),  lr = learning_rate)\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}') # we use method item() to return a float\n",
        "\n",
        "# Training\n",
        "for epoch in range(n_iters):\n",
        "    # prediction = forward pass\n",
        "    # for the prediction we simply call the model\n",
        "    # y_pred = forward(X)\n",
        "    y_pred = model(X)\n",
        "\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # gradients = backward pass\n",
        "    # this wiull calculate the gradients respect to w\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "\n",
        "    # we do not need to optimise the weights manually anymore, I can use an optimiser.step operation\n",
        "    '''\n",
        "        with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    '''\n",
        "    optimizer.step()\n",
        "\n",
        "    # we still have to zero the gradients\n",
        "    # we must zero the gradients, otherwise each iteration the gradient will be calculted and accumulate in w.grad attribute\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 1 ==0: # I am printing every step)\n",
        "        # if we want to print the again we have to unpack them\n",
        "        [w, b] = model.parameters() # this will return a list of list for the weights and a list for the bias\n",
        "        # print('b =', b.item())\n",
        "        # print(f'epoch{epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "        print(f'epoch{epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "id": "UwpxYvM_sGl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7-Linear Regression**"
      ],
      "metadata": {
        "id": "TmUCbMsnsgTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output size, forward pass)\n",
        "# 2) Construct loss and optimiser\n",
        "# 3) Training loop\n",
        "#   - forward pass: compute prediction and loss\n",
        "#   - backward pass: gradients\n",
        "#   - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn # we import the neural network module\n",
        "import numpy as np # for data transformation\n",
        "from sklearn import datasets # we want to generate a regression dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 0) prepare data\n",
        "# Let's generate a regression dataset\n",
        "\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise=20, random_state=1)\n",
        "print(X_numpy)\n",
        "print(y_numpy)\n",
        "# we need to convert the numpy array from double to float\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "# we need to re-shape our y as the whole shape from dataset is only one array containing 100 values.\n",
        "# we can do in 2 different ways\n",
        "# y = y.view(-1, 1)\n",
        "y = y.view(y.shape[0], 1)\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "\n",
        "# 1) model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) loss and optimizer\n",
        "# we use a built in loss function from PyTorch\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "# 3) training loop\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    # forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    #reset gradients because any time we call the backward function it will sum up the gradients in the .grad attribute\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        w, b = model.parameters()\n",
        "        # print(w.shape)\n",
        "        #' print(b.shape)\n",
        "        print(f'epoch{epoch+1}, loss = {loss.item():.4f}, weight = {w[0][0].item():.4f}')\n",
        "\n",
        "\n",
        "# plot\n",
        "# let's get all the predicted values, we call out final model.\n",
        "# in model we have the required_grad attribute set to true, so we wanto to generate a new tensor where the required_grad attribute is set to false\n",
        "# we convert to numpy\n",
        "\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy,  'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aHQq7pM4soW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8-Logistic Regression**"
      ],
      "metadata": {
        "id": "z87igcJ_spG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output size, forward pass)\n",
        "# 2) Construct loss and optimiser\n",
        "# 3) Training loop\n",
        "#   - forward pass: compute prediction and loss\n",
        "#   - backward pass: gradients\n",
        "#   - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler # class used to scale out features\n",
        "# from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#0) Prepare the data\n",
        "# it is a binary classification problem where we can predict cancer based on the existing features\n",
        "# this will return a sklearn Bunch class. Bunch is a subclass of Dict\n",
        "bc = datasets.load_breast_cancer()\n",
        "# print(bc)\n",
        "#' print(type(bc))\n",
        "X, y = bc.data, bc.target\n",
        "# X.shape is tellgn me\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "# Standard scaler will make our features to have 0 mean and unit variance, this is recommended to do when you work with logistic regression\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "# we are not repeating the fit step whcih determines the standard deviation and the mean. they are stored in StandardScaler from the function called before\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# transporm to tensor\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "# reshape our y tensor so that as now I just have one row and we want to make it a column vector, so we want to put each value in one row with just one column\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test= y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) model\n",
        "# our model is a comoination of weights an d bias, then in the logistc regression we appl a sigmoid function at the end\n",
        "# f = wx +b, sigmoid at the end\n",
        "# we will create out own model\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        # we build our model, the first layer is a linear model which only has one value (one class labed) at the end as output\n",
        "        # we will have at the end 30 input features and 1 output features\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_predicted = torch.sigmoid(self.linear(x))\n",
        "        return y_predicted\n",
        "\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "# 2) loss and optiizer\n",
        "criterion = nn.BCELoss()\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#3)\n",
        "num_epochs = 50000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # forward pass and loss\n",
        "    y_predicted = model((X_train))\n",
        "    loss = criterion(y_predicted, y_train)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    #update the weights - pytorch will do all the calculation for us\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1)%10 ==0:\n",
        "        print(f'epoch{epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "# let's evaluate th emodel\n",
        "# the evluation shoudl not be part of or computational graph where wewnt ot track th ehosotry\n",
        "with torch.no_grad(): # if we don't use no_grad the model this will part of the computatipnal grapgh, it will track the gradient\n",
        "    y_predicted = model(X_test)\n",
        "    print(type(y_predicted))\n",
        "    # let's convert to class labels 0 or 1\n",
        "    # the sigmoid function will return a value between 0 and 1\n",
        "    # if it is larger than 0.5 is class 1 otherwise is class 0\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    print(type(y_predicted_cls.eq(y_test)))\n",
        "    print(type(y_predicted_cls.eq(y_test).sum()))\n",
        "    acc = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0]) # y_test.shape[0] will return the number of samples\n",
        "    print('type acc is: ', type(acc))\n",
        "    # acc is a tensor with just one value\n",
        "    print(f'accuracy = {acc:.2f}') # OR  print(f'accuracy = {acc.item():.2f}')\n"
      ],
      "metadata": {
        "id": "FztYhKfcssqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9-Dataset Dataloader**"
      ],
      "metadata": {
        "id": "sR20XV2xsvWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output size, forward pass)\n",
        "# 2) Construct loss and optimiser\n",
        "# 3) Training loop\n",
        "#   - forward pass: compute prediction and loss\n",
        "#   - backward pass: gradients\n",
        "#   - update weights\n",
        "\n",
        "\n",
        "# a better way to use the dataset is to divide the whole training data set into smaller batches\n",
        "# this way we loop over the epochs again and then we loop over all the batches\n",
        "# and then we get the x and y batch and we do the optimization based only on those batches\n",
        "# pytorch can do the batch calculatio and iteration for us\n",
        "\n",
        "# TERMS #\n",
        "# epoch = 1 forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples in one forward and backward pass\n",
        "# number of iterations = number of passes, each pass using [batch_size] number of samples\n",
        "# e.g. 100 samples, batch_size = 20 --> 100/20 = 5 iterations for 1 epoch\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# we can start implementing our own dataset which must inherit the pytorch Dataset class\n",
        "DATA_SRC = 'C:\\\\temp\\\\python\\\\python_working_with_data\\\\pytorchTutorial-master\\\\data\\\\wine\\\\wine.csv'\n",
        "# we want to predict the wine categories, we have 3 categoroes 1, 2, 3 in the first colum, the other columns are the features\n",
        "# let's load and split our columnts into X and y\n",
        "\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "    # we must implement 3 things:\n",
        "    def __init__(self):\n",
        "        # data loading\n",
        "        xy = np.loadtxt(DATA_SRC, delimiter=',', dtype = np.float32, skiprows=1)\n",
        "        # let's split the whole dataset into X and y\n",
        "        # we are using slicing, we want all the samples but we do not want the first column in the inner array -> 1: from the first column all the way till the end\n",
        "        self.x = torch.from_numpy(xy[:, 1:]) # we also convert to torch\n",
        "        # for y we want tbhe first column and we want to wrp ainside an array as I want an array of arrays (a colmun vector) as opposed to an array of values\n",
        "        self.y = torch.from_numpy(xy[:, [0]]) # this way we have a column vectoer which has size n_samples, 1\n",
        "        # we also get the number of samples\n",
        "        self.n_samples = xy.shape[0] # number of samples is the first numebr of the tuple returned by shape\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index] # this will return a tuple\n",
        "        # this will allow for indexing later, we can call dataset with an index e.g. dataset[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "        # this will return the length of the dataset\n",
        "        # len(dataset)\n",
        "\n",
        "\n",
        "\n",
        "dataset = WineDataset()\n",
        "\n",
        "# let's have a look at the very first sample\n",
        "first_data = dataset[0]\n",
        "print(first_data)\n",
        "print(type(first_data)) # data type is a tuple of torch tensors\n",
        "features, labels = first_data[0], first_data[1]\n",
        "print(features) # data type is a tensor\n",
        "print(labels) # data type is a tensor with just one number\n",
        "\n",
        "# now we are going to use a dataloader\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True) # num_workers set to 2 might make the process faster as it is using multiple sub-processes. shuffle set to true is very useful durign training. num_workers=2 creates an issue on this PC\n",
        "\n",
        "\n",
        "# we are going to see an example of data in the dataloader\n",
        "# now we are using this data loader and we will convert it to an iterator\n",
        "datatiter = iter(dataloader)\n",
        "\n",
        "# now we call a next function\n",
        "# data = datatiter.next() this i sthe syntax in pytorch 1.12\n",
        "# from pytorch 1.13 the only working syntax is:\n",
        "data = next(datatiter)\n",
        "# we will unpack it again\n",
        "print(data)\n",
        "print(type(data))\n",
        "features, labels = data[0], data[1] # i could have wriiten this as:  features, labels = data\n",
        "print(features)\n",
        "print(type(features))\n",
        "print(labels)\n",
        "print(type(labels))\n",
        "\n",
        "\n",
        "# let's define some hyper-parameters\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "batch_size = 4\n",
        "# lets get the number of iterations for each epoch (this will be total number of sampela divided by the bacth size)\n",
        "n_iterations = math.ceil(total_samples/batch_size) # we need to use match cei as without we would get 44.5 iteration, with math.ceil this will be 45\n",
        "print('total sample: ', total_samples, ' number iterations: ', n_iterations)\n",
        "\n",
        "# let's write some dummy training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        # forward backward, upadte\n",
        "        if (i+1) % 5 == 0: # every 5th step I want to print some information\n",
        "            print(f'epoch {epoch + 1 }/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n",
        "\n",
        "\n",
        "\n",
        "# pytorch has some built in datasets,\n",
        "\n",
        "dataset = torchvision.datasets.MNIST('aaaa', download=True)\n",
        "print(dataset)\n",
        "print(type(dataset))\n"
      ],
      "metadata": {
        "id": "TCUTSAP9sx25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10-Dataset Transform**"
      ],
      "metadata": {
        "id": "xcCRETMks2nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "# if we use a torch built in dataset we can pass a transform argument to concert to Tensor and apply some transforms\n",
        "# in this case we use the MNSIT dataset and we aplly the ToTensor() transform whi will convert numpy arrays or images into Tensor\n",
        "# pytorch has alrealy a lot of transform implemented for us, the official documentation is:\n",
        "# https://pytorch.org/vision/stable/transforms.html\n",
        "\n",
        "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
        "during creation of the DataSet\n",
        "\n",
        "On Images\n",
        "---------\n",
        "CenterCrop, Grayscale, Pad, RandomAffine\n",
        "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
        "Resize, Scale\n",
        "\n",
        "On Tensors\n",
        "----------\n",
        "LinearTransformation, Normalize, RandomErasing\n",
        "\n",
        "Conversion\n",
        "----------\n",
        "ToPILImage: from tensor or ndrarray\n",
        "ToTensor : from numpy.ndarray or PILImage\n",
        "\n",
        "Generic\n",
        "-------\n",
        "Use Lambda\n",
        "\n",
        "Custom\n",
        "------\n",
        "Write own class\n",
        "\n",
        "Compose multiple Transforms\n",
        "---------------------------\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# in the last tutorial we created a custom WineDataset class, now we are extending this class to apply our own transforms and apply our own transfer classes\n",
        "\n",
        "\n",
        "\n",
        "# we can start implementing our own dataset which must inherit the pytorch Dataset class\n",
        "DATA_SRC = 'C:\\\\temp\\\\python\\\\python_working_with_data\\\\pytorchTutorial-master\\\\data\\\\wine\\\\wine.csv'\n",
        "# we want to predict the wine categories, we have 3 categoroes 1, 2, 3 in the first colum, the other columns are the features\n",
        "# let's load and split our columnts into X and y\n",
        "\n",
        "# this class will load the data in the init constructor method, then we implemented the getitem whci will allow indexing\n",
        "# now we will extend the dataset, so our class should also support the transform argument which is optional so at the beginnign we say None\n",
        "# we want to make a change to the getitem method, so we can apply a transfor if available.\n",
        "class WineDataset(Dataset):\n",
        "    # we must implement 3 things:\n",
        "    def __init__(self, transform = None):\n",
        "        # data loading\n",
        "        xy = np.loadtxt(DATA_SRC, delimiter=',', dtype = np.float32, skiprows=1)\n",
        "        # let's split the whole dataset into X and y\n",
        "        # we are using slicing, we want all the samples but we do not want the first column in the inner array -> 1: from the first column all the way till the end\n",
        "        # self.x = torch.from_numpy(xy[:, 1:]) # we also convert to torch\n",
        "        # for y we want tbhe first column and we want to wrp ainside an array as I want an array of arrays (a colmun vector) as opposed to an array of values\n",
        "        # self.y = torch.from_numpy(xy[:, [0]]) # this way we have a column vectoer which has size n_samples, 1\n",
        "        # we also get the number of samples\n",
        "\n",
        "        # we are not converting to tensor here as we are going to use our custom transofrm class ToTensor()\n",
        "        self.x = xy[:, 1:]\n",
        "        self.y = xy[:, [0]]\n",
        "        self.n_samples = xy.shape[0] # number of samples is the first numebr of the tuple returned by shape\n",
        "\n",
        "        self.transform = transform # by default this attribute can be None\n",
        "\n",
        "    # we want to make a change to the getitem method, so we can apply a transfor if available.\n",
        "    def __getitem__(self, index):\n",
        "        # with tranform I am going to mage this change\n",
        "        # return self.x[index], self.y[index] # this will return a tuple\n",
        "        # this will allow for indexing later, we can call dataset with an index e.g. dataset[0]\n",
        "        sample = self.x[index], self.y[index]\n",
        "\n",
        "        if self.transform: # if transform not None (python considers None equal to False)\n",
        "            sample = self.transform(sample)\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "        # this will return the length of the dataset\n",
        "        # len(dataset)\n",
        "\n",
        "    # we can now create some custom transform classes\n",
        "    # we can write out own ToTensor class\n",
        "    # the only thing we need to implement is the __call__method\n",
        "class ToTensor():\n",
        "    def __call__(self, sample): # this will became a callable object which will perform an action when it is called\n",
        "        # we unpack our sample\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets) # we will return a tuple\n",
        "\n",
        "\n",
        "# now we can use the transform in our dataset\n",
        "dataset = WineDataset(transform = None)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n",
        "\n",
        "# now we can use the transform in our dataset\n",
        "dataset = WineDataset(transform = ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "\n",
        "# if we set the atrribute transform to None the datatype wil lbe a numpy ndarray\n",
        "\n",
        "#let's write another tranformation class\n",
        "class MulTransform():\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor # the constructor takes one parameter which is the number we are mutiplying for\n",
        "\n",
        "    def __call__(self, sample):\n",
        "          inputs, targets = sample\n",
        "          # we will only multiply the features\n",
        "          inputs *= self.factor\n",
        "          return inputs, targets\n",
        "\n",
        "\n",
        "# let's aplly a composed transfom to use both transform classes\n",
        "# we pass a list with all our transforms\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
        "\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features) # each value was doubled with respect to the dataset where transform is set to None\n",
        "print(type(features), type(labels))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q0uN1ZBvs6li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11-Softmax Cross Entropy**"
      ],
      "metadata": {
        "id": "_czDOwlfs-lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax basically squashes the output to be between 0 and 1\n",
        "# say we have a linear layer which return 2.0, 1.0, 0.1. we then apply the softmaw which squashes these values to 0.7, 0.2, 0.1 (returns the probability of each value)\n",
        "# we can then choose the class with the highest probability\n",
        "\n",
        "# let's see an implementatio of the softmax function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x)/np.sum(np.exp(x), axis = 0)\n",
        "    # for a 1 dimentional array axis=0 sums all the values, for a 2-min array sums all the values vertically (axis=1 horizontally)\n",
        "    # https://stackoverflow.com/questions/40200070/what-does-axis-0-do-in-numpys-sum-function\n",
        "\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy', outputs)\n",
        "\n",
        "# we can calculate the softmax in pytorch\n",
        "x = torch.tensor([2.0, 1.0, 0.1], dtype = torch.float32)\n",
        "outputs = torch.softmax(x, dim=0) # we need to specify the direction so it computes along the first axis\n",
        "print('softmax torch', outputs)\n",
        "\n",
        "# the softmax is often combined with the cross entropy loss\n",
        "# cross-entropy can be used in an multu class problem\n",
        "# the cross-entropy is a measure of how far we are from the one hot encoding vector, the farther the higher the cross entropy\n",
        "\n",
        "# an implementation of the cross entropy functoin with numpy is as follows\n",
        "\n",
        "def cross_entropy(actual, predicted):\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # float(predicted.shape[0]) - we could normalize dividing by the number of samples but we are not doing it here\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1, 0, 0]\n",
        "# if class 1: [0, 1, 0]\n",
        "# if class 2: [0, 0, 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "\n",
        "# y_pred has probabilities\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}') # the loss is  much higher (sample is very different form the one-hot encoded vector)\n",
        "\n",
        "\n",
        "# let's look at pytorch implemetation for cross entropy\n",
        "# careful!!\n",
        "# mm.CrossEntropyLoss applies nn.LogSoftmax + nn.NLLLoss (negative log likelihood loss)\n",
        "# -> No Softmax in the last layer\n",
        "# Y has class labels, not one-Hot (I should only put the correct class label)\n",
        "# Y_pred has raw scores (logits), no softmax\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "Y = torch.tensor([0]) # -> the true resutl is class 0 not one hote encoded anymore\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]]) # careful!! this tensor has the size n_sample x n_classes (in this case we have 1 sample and 3 possible classes) -> we use the raw value, we don't apply the softmax\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]]) # this is a bad prediction\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(l1.item()) # I am calling the item method as the tensor has only one value\n",
        "print(l2.item())\n",
        "\n",
        "# _, because we do nto need this\n",
        "_, predictions1 = torch.max(Y_pred_good, 1) # we want the max along the first dimension\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1) # we want the max along the first dimension\n",
        "print(predictions1) # in this case we choose class no. 0\n",
        "print(predictions2) # in this case we choose class no. 1\n",
        "\n",
        "# the loss in pytorch allow for multiple samples\n",
        "# 3 samples and 3 possible classes\n",
        "\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "#  n_sample x n_classes\n",
        "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1],[2.0, 1.0, 0.1],[0.1, 3.0, 0.1]]) # for example for the 2nd sample the value for the 0 class has the highest value\n",
        "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1],[1.0, 1.0, 2.1],[0.1, 3.0, 0.1]]) # for example for the 2nd sample the value for the 0 class has the highest value\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(l1.item()) # I am calling the item method as the tensor has only one value\n",
        "print(l2.item())\n",
        "\n",
        "# _, because we do nto need this, torch.max return a tuple, we want to ignore the first value\n",
        "# without _, this woudl return\n",
        "'''\n",
        "torch.return_types.max(\n",
        "values=tensor([2.1000, 2.0000, 3.0000]),\n",
        "indices=tensor([2, 0, 1])) # item at index #2 is the max\n",
        "'''\n",
        "_, predictions1 = torch.max(Y_pred_good, 1) # we want the max along the first dimension #\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1) # we want the max along the first dimension\n",
        "print(predictions1) # in this case we choose class no. 0\n",
        "print(predictions2) # in this case we choose class no. 1 # we get the corrct prediciotn only for the 3rd sample\n",
        "\n",
        "\n",
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jOUCTKRctEsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12-Plot Activation Functions**"
      ],
      "metadata": {
        "id": "pqoKo5oWtGYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# activations functions decide whether a neuron should be activated or not\n",
        "# without activation functions the neural network would just be a stacked liner model\n",
        "\n",
        "\n",
        "\n",
        "##### Sigmoid typically used in the last layer of a binary classification problem\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,100)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(y,sigmoid(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Sigmoid Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-2, -1, 0, 1, 2])\n",
        "\n",
        "plt.ylim(-2, 2)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('sigmoid.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "##### TanH\n",
        "tanh = lambda x: 2*sigmoid(2*x)-1\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,100)\n",
        "\n",
        "plt.plot(y,tanh(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('TanH Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('tanh.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "##### ReLU # it wil output innputs for values > 0 and return 0 otherwise\n",
        "# MOST USED!!! rule of thum, if you do not know what value ot use, then use RELU as activation function for hidden layer\n",
        "relu = lambda x: np.where(x>=0, x, 0)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,relu(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('ReLU')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('relu.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "##### Leaky ReLU\n",
        "# slightly modified and imporved version of the RELU function, trying to solve the problem of the vanishing problem\n",
        "# when you see wrights are not updating trying use the LEaky RELU as opposed to the RELU\n",
        "leakyrelu = lambda x: np.where(x>=0, x, 0.1*x)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,leakyrelu(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Leaky ReLU')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('lrelu.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "##### Binary Step\n",
        "bstep = lambda x: np.where(x>=0, 1, 0)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,bstep(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Step Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-2, -1, 0, 1, 2])\n",
        "\n",
        "plt.ylim(-2, 2)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('step.png')\n",
        "\n",
        "print('done')"
      ],
      "metadata": {
        "id": "Bo6ZzcBntLC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13-Feed Forward Network**"
      ],
      "metadata": {
        "id": "Vylirv5itV3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST\n",
        "# Dataloader, Transformation\n",
        "# Multilayer Neural Net, activation function\n",
        "# Loss and Optimizer\n",
        "# Training Loop (batch training)\n",
        "# Model evaluation\n",
        "# GPU support\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# we will push our tensors on the device and thsi will guaranteer it will run on the GPU if it is supported\n",
        "\n",
        "# let's define some hyper parameters\n",
        "input_size = 784 # this is because our images have a size 28x28, then we will flat this array to be a 1-D tensor\n",
        "# let's define a hidden-size\n",
        "hidden_size = 100\n",
        "num_classes = 10 # we have digits from 0 to 9\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# let's import the famous MNIST dataset from the torch library\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root = './data', transform=transforms.ToTensor(), train = True, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root = './data', transform=transforms.ToTensor(), train = False) # no need to download it again\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False) # no need to shuffle the data for testing\n",
        "\n",
        "# let's have a look at an example of this dataset\n",
        "examples = iter(train_loader)\n",
        "samples, labels = next(examples)\n",
        "print(samples.shape, labels.shape) # sample will have a shape [100, 1, 28, 28] -> 100 samples (our batch size is 100), 1 channel (only gray colour), width and depth of pics\n",
        "\n",
        "\n",
        "\n",
        "for i in range (6):\n",
        "    plt.subplot(2, 3, i+1) # i+1 is for the position of the picture in the 2 x 3 array\n",
        "    plt.imshow(samples[i][0], cmap='gray')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# we want to classify these digits, for this we want to setup a fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module): # the class must be derived from nn.Module\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # we create our layers\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "\n",
        "        # we have to be careful as we do not want to apply the softmax function which is included in the Cross Entropy loss\n",
        "        return out\n",
        "\n",
        "# we call out model\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "\n",
        "# we create the loss and out optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# now we can do our training loop\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader): # the data is a tuple of the images\n",
        "        # we need to reshape our images first as if we have a look at the shape this is 100, 1, 28, 28\n",
        "        # our input size is 784, out image tensor needs the size 100, 784\n",
        "        # we need to reshare out tensor first\n",
        "        images = images.reshape(-1, 28*28).to(device)# we will push it to the device if available\n",
        "        labels = labels.to(device) # we also push the lables to device\n",
        "\n",
        "        # forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backwards\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'epoch{epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss= {loss.item():.4f}')\n",
        "\n",
        "# test\n",
        "# for testign we do not want to compute the gradient\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)# we will push it to the device if available\n",
        "        labels = labels.to(device) # we also push the lables to device\n",
        "        outputs = model(images)\n",
        "\n",
        "        # we return the value and th eindex, we are just interested in the index, so we skip the values\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        n_samples += labels.shape[0] # this will give the number of samples in th batch, it shold be 100\n",
        "        n_correct += (predictions.eq(labels)).sum().item()\n",
        "        print(n_correct)\n",
        "    print('num samples', n_samples)\n",
        "    print('n_correct', n_correct)\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "id": "rvUn8B6dtbeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14-CNN**"
      ],
      "metadata": {
        "id": "RxR8_dVgtdYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "Yv7juuuwtgTN",
        "outputId": "8c2a37bd-ee0f-412e-9ed7-b2c0179417b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170498071/170498071 [00:03<00:00, 42987910.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.2920\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.2955\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.3044\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d40a66633b60>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}